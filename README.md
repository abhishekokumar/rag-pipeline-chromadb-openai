# Retrieval-Augmented Generation (RAG) Pipeline with ChromaDB

## üìå Project Overview

This project implements a **baseline Retrieval-Augmented Generation (RAG) system** that retrieves semantically relevant document chunks from a vector database and answers user queries **only when the information is grounded in the retrieved context**.

The primary goal of this repository is to demonstrate a **clear, correct, and explainable RAG foundation**, while continuously extending it with more advanced RAG concepts as learning progresses.

---

## üß† Key Concepts Demonstrated

- Document ingestion and preprocessing  
- Text chunking for semantic retrieval  
- Vector embeddings using OpenAI  
- Vector similarity search using cosine similarity  
- Context-grounded question answering  
- Awareness and handling of hallucination scenarios  

---

## üèóÔ∏è High-Level Architecture

```
Documents (.txt)
      ‚Üì
Text Loading (DirectoryLoader)
      ‚Üì
Chunking (CharacterTextSplitter)
      ‚Üì
Embeddings (OpenAI text-embedding-3-small)
      ‚Üì
ChromaDB (Vector Store)
      ‚Üì
Cosine Similarity Search (Top-k)
      ‚Üì
Grounded Answer Generation
```

---

## üìÇ Project Structure

```
rag-pipeline/
‚îÇ
‚îú‚îÄ‚îÄ docs/                     # Knowledge base documents (.txt)
‚îÇ
‚îú‚îÄ‚îÄ ingestion_pipeline.py     # Document loading, chunking, embedding, storage
‚îú‚îÄ‚îÄ retrieval_pipeline.py     # Query embedding and similarity-based retrieval
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

> Note: Local artifacts such as `venv/`, persisted vector databases, and `.env` files are intentionally excluded from version control.

---

## üîç Retrieval Strategy

- **Embedding Model:** `text-embedding-3-small`
- **Vector Store:** ChromaDB  
- **Similarity Metric:** Cosine similarity  
- **Top-k Retrieval:** Configurable (default: top 3 chunks)

The **same embedding model** is used for both document chunks and user queries to ensure embedding-space consistency.

---

## üîÅ Retrieval & Answer Generation Enhancements

- Implemented **LLM-based answer generation strictly grounded in retrieved context**, preventing the model from introducing external knowledge.
- Explored and integrated multiple retrieval strategies to improve answer reliability and recall:
  - **MMR (Maximal Marginal Relevance):** diversity-aware retrieval to reduce redundancy in retrieved chunks
  - **Similarity score thresholding:** rejection of low-confidence context to avoid unsupported answers
  - **Multi-query retrieval:** improved recall for ambiguous or underspecified user queries

---

## ‚ö†Ô∏è Hallucination Awareness

If the retrieved context **does not explicitly contain the answer**, the system responds with:

> *The information is not available in the provided documents.*

This behavior aligns with real-world RAG safety best practices.

---

## ‚úÖ Example Behavior

| User Query | Retrieved Context | System Response |
|-----------|------------------|-----------------|
| Tesla Roadster production year | Present | Correct answer returned |
| SpaceX Pacific island lease | Not present | Not available in provided documents |

---

## üöß Project Status

**Ongoing / Actively Evolving**

This repository starts with a baseline RAG implementation and will be progressively extended with advanced concepts such as:
- Retrieval quality tuning  
- Similarity score thresholds  
- Re-ranking strategies  
- Evaluation pipelines  
- Advanced RAG architectures  

---

## üõ†Ô∏è Setup Instructions

### 1Ô∏è‚É£ Clone the repository
```bash
git clone https://github.com/your-username/rag-pipeline-chromadb-openai.git
cd rag-pipeline-chromadb-openai
```

### 2Ô∏è‚É£ Create a virtual environment
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 3Ô∏è‚É£ Install dependencies
```bash
pip install -r requirements.txt
```

### 4Ô∏è‚É£ Configure environment variables
Create a `.env` file based on `.env.example`:

```
OPENAI_API_KEY=your_api_key_here
```

---


## üìå Author

Abhishek Kumar  
MSc Data Science & Analytics  

